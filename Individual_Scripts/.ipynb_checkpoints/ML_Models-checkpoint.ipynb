{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "062aedcd",
   "metadata": {},
   "source": [
    "## Machine Learning Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8901a0f",
   "metadata": {},
   "source": [
    "### 1. Rating as Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46773c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(RatingCount_Cat_Model.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5d6be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is your features list\n",
    "# Y is your target Variable what you are trying to predict\n",
    "\n",
    "# when you know what you are trying to predict then it is called as supervised learning (do change if this doesnt make sense or \n",
    "# if it is not correct)\n",
    "\n",
    "#Note: Never Put the column that you are trying predict or something that is closly/directly related to it.. in feature (i.e \"x\").\n",
    "# If you are trying to predict ratingtype and you keep it in features(i.e 'x') they model might get 100% accuray while is false \n",
    "# or incorrect way to build a model\n",
    "\n",
    "# there are other concepts like over fiting and under fiting of the model to get more accuracy (need to explore if required or interested)\n",
    "\n",
    "X1 = RatingCount_Cat_Model.drop(['App','Size','Released' ,'Type','Last_Updated','Released_day',\n",
    " 'Released_month',\n",
    " 'Released_year',\n",
    " 'LU_day',\n",
    " 'LU_month',\n",
    " 'LU_year',\n",
    " 'App Age',\n",
    " 'Install Per Year','App Id','RatingCount',\n",
    "'RatingType'],axis=1)\n",
    "y1 = RatingCount_Cat_Model['RatingType'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5795f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X1.drop(['Develop_Id','Main Category'],axis=1) # Droped the column \"Main Category\" because it is categorical variable which is string\n",
    "# and model cant accept these kind of elemets in.\n",
    "list(X1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3558702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below commented part i.e LabelEncoder() and StandardScaler is to make the data of a column to \n",
    "# fit into model by converting them to numeric values if something in the column has string. \n",
    "# Below methods (LabelEncoder(),StandardScaler()) can be used to in case of any error occurs saying \"String....\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85344a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X1.drop(['Rating'],axis=1)\n",
    "number = preprocessing.LabelEncoder()\n",
    "#X['Category'] = number.fit_transform(X.Category)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X1['Install'] = scaler.fit_transform(X1[['Install']])\n",
    "\n",
    "\n",
    "# This is method can be used to pass in the column and convert them to numeric values so the model wont throw erorr.\n",
    "# As we alread converted the data in to numeric, this is not necessary at the momment\n",
    "\n",
    "#from sklearn import preprocessing\n",
    "#def convert(data):\n",
    "    #number = preprocessing.LabelEncoder()\n",
    "    #data['Employer_Name'] = number.fit_transform(data.Employer_Name)\n",
    "    #data['Source'] = number.fit_transform(data.Source)\n",
    "    #data=data.fillna(-999)\n",
    "    #return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab21c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are splitting the code into train data and test data using \"train_test_split\"\n",
    "# (X,y) (features, traget) \n",
    "# stratify this is to preserve the proportion of target as in original dataset below\n",
    "# we have \"stratify=y\", that means in train & test datasets the target proportion\n",
    "# below method returns 70:30 split (Train:Test) because we have set test_size=0.3, \n",
    "# i.e the test_size is to determine the split proportion\n",
    "# random_state is to set the randomness of the train:test generation each time the slipt function runs\n",
    "# if we set 0 every it will be the same but if we change it. it will produce %randomness in the produced set \n",
    "X_train,X_test,y_train,y_test = train_test_split(X1,y1,stratify=y,test_size=0.3,random_state=20)\n",
    "\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d9c308",
   "metadata": {},
   "source": [
    "### a) Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94da5a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple RandomForestClassifier without any parameter tuning\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train,y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "rf_acc = accuracy_score(y_pred,y_test)*100 # Acurracy Score\n",
    "print(\"Accuracy =\",round(rf_acc,2),\"%\") # Acurracy \n",
    "cm = confusion_matrix(y_pred,y_test)\n",
    "\n",
    "cmd = ConfusionMatrixDisplay(cm,display_labels =['Avg','Good','Better'])\n",
    "fig, ax = plt.subplots(figsize=(12,12));\n",
    "plt.title(\"Confusion Matrix RandomForestClassifier\")\n",
    "cmd.plot(ax=ax);\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7840d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a question comes up what is parameter tuning or what are the parameters that can be tuned?\n",
    "# List of parameters that can be tuned - learning_rate = 0.05, max_depth = 8, n_estimators = 400, verbose =1\n",
    "# input values can be changed as per requirement which might increase or reduce the time taken to get prediction from the model\n",
    "# We can do paramter tuning using gridsearchcv method from sklearn which at the end gives you best parameter which will help the tunning\n",
    "# Example we can give a list of parameters and after running through all those thing \"gridsearchcv\" lets us know the \n",
    "# best parameters based on accurary or F1-score or what ever metric we choose. \n",
    "# param_grid = {\n",
    "#    \"learning_rate\": [0.01,0.025, 0.05],\n",
    "#    \"max_depth\":[5,8,10],\n",
    "#    \"n_estimators\":[25, 50, 100],\n",
    "#    \"verbose\":[1]\n",
    "#    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b826dd",
   "metadata": {},
   "source": [
    "#### Classification Report for Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3060646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to print out the report which will gives use other metrics like precision, f1-score, support scores \n",
    "# which will help us evaluate the model\n",
    "\n",
    "target_names = ['Avg','Good','Better']\n",
    "cr = classification_report(y_test,y_pred,target_names = target_names)\n",
    "print(\"Classification Report for RandomForestClassifier\")\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9b53a7",
   "metadata": {},
   "source": [
    "### b) Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ef71f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note : once a model is built (i.e \"x\" & \"Y\") we need to use the same for all the different classifiers. We should not change them\n",
    "# so that we can compared and say we are not just relaying on single calssifer we are using multiple and we can compare their accuracy\n",
    "\n",
    "#GradientBoostingClassifier\n",
    "\n",
    "gb_model = GradientBoostingClassifier()\n",
    "gb_model.fit(X_train,y_train)\n",
    "y_pred = gb_model.predict(X_test)\n",
    "gb_acc = accuracy_score(y_pred,y_test)*100\n",
    "print(\"Accuracy =\",round(gb_acc,2),\"%\")\n",
    "cm = confusion_matrix(y_pred,y_test)\n",
    "X_Tick_List=['Avg','Good','Better']\n",
    "cmd = ConfusionMatrixDisplay(cm,display_labels =['Avg','Good','Better'])\n",
    "fig, ax = plt.subplots(figsize=(12,12));\n",
    "plt.title(\"Confustion Matrix for GradientBoostingClassifier\")\n",
    "cmd.plot(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e567e671",
   "metadata": {},
   "source": [
    "#### Classification report for Gradient Boosting Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79829de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report\n",
    "\n",
    "target_names = ['Avg','Good','Better']\n",
    "cr = classification_report(y_test,y_pred,target_names = X_Tick_List)\n",
    "print(\"Classification Report for GradientBoostingClassifier\")\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25cc799",
   "metadata": {},
   "source": [
    "### c) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df76b257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "\n",
    "lr_c=LogisticRegression(random_state=0)\n",
    "lr_c.fit(X_train,y_train)\n",
    "lr_pred=lr_c.predict(X_test)\n",
    "lr_cm=confusion_matrix(lr_pred,y_test)\n",
    "#cm = confusion_matrix(y_pred,y_test)\n",
    "\n",
    "cmd = ConfusionMatrixDisplay(lr_cm,display_labels =['Avg','Good','Better'])\n",
    "fig, ax = plt.subplots(figsize=(12,12));\n",
    "plt.title(\"Confustion Matrix for GradientBoostingClassifier\")\n",
    "cmd.plot(ax=ax);\n",
    "lr_ac=accuracy_score(lr_pred, y_test)\n",
    "print('LogisticRegression_accuracy:',lr_ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee57614",
   "metadata": {},
   "source": [
    "#### Classification report for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c9f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report\n",
    "\n",
    "target_names = ['Avg','Good','Better']\n",
    "cr = classification_report(y_test,y_pred,target_names = X_Tick_List)\n",
    "print(\"Classification Report for LogisticRegression\")\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adec06cc",
   "metadata": {},
   "source": [
    "### 2. Installs as Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2e22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Install_Cat_Model=Permission\n",
    "list(Permission.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5162ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below we care using pd.factorize, astype(int) to change the features into numeric values for the model\n",
    "# because model doesnt accept any string formates into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef03eec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Install_Cat_Model['Category'] = pd.factorize(Install_Cat_Model['Category'])[0].astype(int)\n",
    "\n",
    "#Install_Cat_Model['Type'] = np.where(Install_Cat_Model['Free'] == True,'Free','Paid')\n",
    "#Install_Cat_Model.drop(['Free'],inplace=True,axis=1)\n",
    "\n",
    "Install_Cat_Model['Type'] = pd.factorize(Install_Cat_Model['Type'])[0].astype(int)\n",
    "Install_Cat_Model['Content Rating'] = pd.factorize(Install_Cat_Model['Content Rating'])[0].astype(int)\n",
    "Install_Cat_Model['Ad_Supported'] = pd.factorize(Install_Cat_Model['Ad_Supported'])[0].astype(int)\n",
    "Install_Cat_Model['Editors_Choice'] = pd.factorize(Install_Cat_Model['Editors_Choice'])[0].astype(int)\n",
    "Install_Cat_Model['In_App_Purchases'] = pd.factorize(Install_Cat_Model['In_App_Purchases'])[0].astype(int)\n",
    "\n",
    "Install_Cat_Model['PriceRange'] = pd.cut(Install_Cat_Model['Price'],bins=[0,0.19,9.99,29.99,410],labels=['Free','Low','Mid','High'],include_lowest=True)\n",
    "#dummies = pd.get_dummies(df['PriceRange'],prefix='Price')\n",
    "#df = df.join(dummies)\n",
    "Install_Cat_Model['PriceRange'].value_counts()\n",
    "\n",
    "\n",
    "#Reason to add/build a new column which catergories the column which you wanna predict is to reduced the load on the model so that it can\n",
    "# can work on points/boundaries wich we set... instead of making every pointer to a boundary.\n",
    "# also help us in mapping confusion matrix to evaluate the model better\n",
    "\n",
    "\n",
    "#You can remove this if you want to, because we dont have much use of this \"RatingType\" causing I think we dropped it later.\n",
    "\n",
    "#only reason we are making different data frame for the installs_range and rating_range is to keep it clean and less confusing \n",
    "\n",
    "Install_Cat_Model['RatingType'] = 'NoRating'\n",
    "Install_Cat_Model.loc[(Install_Cat_Model['RatingCount'] > 0) & (Install_Cat_Model['RatingCount'] <= 500000.0),'RatingType'] = 'Up to 500K'\n",
    "#Install_Cat_Model.loc[(Install_Cat_Model['RatingCount'] > 10000) & (Install_Cat_Model['RatingCount'] <= 500000.0),'RatingType'] = 'Between 10K and 500K'\n",
    "Install_Cat_Model.loc[(Install_Cat_Model['RatingCount'] > 500000) & (Install_Cat_Model['RatingCount'] <= 138557570.0),'RatingType'] = 'More than 500K'\n",
    "Install_Cat_Model.RatingType.value_counts()\n",
    "\n",
    "Install_Cat_Model['RatingType'] = pd.factorize(Install_Cat_Model['RatingType'])[0].astype(int)\n",
    "Install_Cat_Model['PriceRange'] = pd.factorize(Install_Cat_Model['PriceRange'])[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d47e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install_Cat_Model['InstallRange'] = '0-100000'\n",
    "Install_Cat_Model.loc[(Install_Cat_Model['Install'] >= 0) & (Install_Cat_Model['Install'] <= 10000000),'InstallRange'] = '0-10000000'\n",
    "#Install_Cat_Model.loc[(Install_Cat_Model['Install'] > 1000000) & (Install_Cat_Model['Install'] <= 10000000),'InstallRange'] = '1000000-10000000'\n",
    "Install_Cat_Model.loc[(Install_Cat_Model['Install'] > 10000000) & (Install_Cat_Model['Install'] <= 1000000000),'InstallRange'] = '10000000-1000000000'\n",
    "#Install_Cat_Model.loc[(Install_Cat_Model['Install'] > 100000000) & (Install_Cat_Model['Install'] <= 1000000000),'InstallRange'] = '100000000-1000000000'\n",
    "Install_Cat_Model.loc[(Install_Cat_Model['Install'] > 1000000000) & (Install_Cat_Model['Install'] <= 10000000000),'InstallRange'] = '1000000000-10000000000'\n",
    "\n",
    "Install_Cat_Model.InstallRange.value_counts()\n",
    "\n",
    "Install_Cat_Model['InstallRange'] = pd.factorize(Install_Cat_Model['InstallRange'])[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7929fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Install_Cat_Model.InstallRange.value_counts()\n",
    "RatingCount_Cat_Model = Install_Cat_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de584152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is your features list\n",
    "# Y is your target Variable what you are trying to predict\n",
    "\n",
    "# when you know what you are trying to predict then it is called as supervised learning (do change if this doesnt make sense or \n",
    "# if it is not correct)\n",
    "\n",
    "#Note: Never Put the column that you are trying predict or something that is closly/directly related to it.. in feature (i.e \"x\").\n",
    "# If you are trying to predict ratingtype and you keep it in features(i.e 'x') they model might get 100% accuray while is false \n",
    "# or incorrect way to build a model\n",
    "\n",
    "# there are other concepts like over fiting and under fiting of the model to get more accuracy (need to explore if required or interested)\n",
    "X = Install_Cat_Model.drop(['App','Size','Released' ,'Type','Last_Updated','Released_day',\n",
    " 'Released_month',\n",
    " 'Released_year',\n",
    " 'LU_day',\n",
    " 'LU_month',\n",
    " 'LU_year',\n",
    " 'App Age',\n",
    " 'Install Per Year','App Id'],axis=1)\n",
    "#y = dfm['RatingType'].values\n",
    "y = Install_Cat_Model['InstallRange'].values\n",
    "\n",
    "#'RatingCount'\n",
    "#'RatingType'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d6f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this might through error but it will about the column which is not present, so what we can do is remove the column from the\n",
    "# below list so that it wont through error or exception\n",
    "# To check the list of columns/features available you can always look up with this \"list(X.columns)\". so that you will know what \n",
    "# are present and what are not there.\n",
    "\n",
    "#Note: Don't try to run this line twice because in the first run it will remove the columns and next time it will throw error \n",
    "#saying that it cant find the column\n",
    "\n",
    "X = X.drop(['RatingType','InstallRange','Develop_Id','Main Category','Install','RatingCount'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f3e8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36aa533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are splitting the code into train data and test data using \"train_test_split\"\n",
    "# (X,y) (features, traget) \n",
    "# stratify this is to preserve the proportion of target as in original dataset below\n",
    "# we have \"stratify=y\", that means in train & test datasets the target proportion\n",
    "# below method returns 70:30 split (Train:Test) because we have set test_size=0.3, \n",
    "# i.e the test_size is to determine the split proportion\n",
    "# random_state is to set the randomness of the train:test generation each time the slipt function runs\n",
    "# if we set 0 every it will be the same but if we change it. it will produce %randomness in the produced set \n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y,test_size=0.3,random_state=20)\n",
    "\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2c897e",
   "metadata": {},
   "source": [
    "### a) Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1686a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple RandomForestClassifier without any parameter tuning\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train,y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "rf_acc = accuracy_score(y_pred,y_test)*100\n",
    "print(\"Accuracy =\",round(rf_acc,2),\"%\")\n",
    "cm = confusion_matrix(y_pred,y_test)\n",
    "\n",
    "#Install_lbl= ['0-100000','100000-1000000','1000000-10000000','10000000-100000000','100000000-1000000000','1000000000-10000000000']\n",
    "Install_lbl=['1M','1-10M','10M-1B']\n",
    "\n",
    "cmd = ConfusionMatrixDisplay(cm,display_labels =['1M','1-10M','10M-1B'])\n",
    "fig, ax = plt.subplots(figsize=(15,15));\n",
    "\n",
    "plt.title(\"Confusion Matrix RandomForestClassifier\")\n",
    "cmd.plot(ax=ax);\n",
    "plt.grid(False)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdda4e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a question comes up what is parameter tuning or what are the parameters that can be tuned?\n",
    "# List of parameters that can be tuned - learning_rate = 0.05, max_depth = 8, n_estimators = 400, verbose =1\n",
    "# input values can be changed as per requirement which might increase or reduce the time taken to get prediction from the model\n",
    "# We can do paramter tuning using gridsearchcv method from sklearn which at the end gives you best parameter which will help the tunning\n",
    "# Example we can give a list of parameters and after running through all those thing \"gridsearchcv\" lets us know the \n",
    "# best parameters based on accurary or F1-score or what ever metric we choose. \n",
    "# param_grid = {\n",
    "#    \"learning_rate\": [0.01,0.025, 0.05],\n",
    "#    \"max_depth\":[5,8,10],\n",
    "#    \"n_estimators\":[25, 50, 100],\n",
    "#    \"verbose\":[1]\n",
    "#    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572041d2",
   "metadata": {},
   "source": [
    "#### Classification Report for RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report\n",
    "\n",
    "# This is to print out the report which will gives use other metrics like precision, f1-score, support scores \n",
    "# which will help us evaluate the model\n",
    "\n",
    "target_names = Install_lbl\n",
    "cr = classification_report(y_test,y_pred,target_names = target_names)\n",
    "print(\"Classification Report for RandomForestClassifier\")\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b08e74",
   "metadata": {},
   "source": [
    "### b) Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8019ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note : once a model is built (i.e \"x\" & \"Y\") we need to use the same for all the different classifiers. We should not change them\n",
    "# so that we can compared and say we are not just relaying on single calssifer we are using multiple and we can compare their accuracy\n",
    "\n",
    "#GradientBoostingClassifier\n",
    "\n",
    "\n",
    "gb_model = GradientBoostingClassifier()\n",
    "gb_model.fit(X_train,y_train)\n",
    "y_pred = gb_model.predict(X_test)\n",
    "gb_acc = accuracy_score(y_pred,y_test)*100\n",
    "print(\"Accuracy =\",round(gb_acc,2),\"%\")\n",
    "cm = confusion_matrix(y_pred,y_test)\n",
    "\n",
    "cmd = ConfusionMatrixDisplay(cm,display_labels =Install_lbl)\n",
    "fig, ax = plt.subplots(figsize=(12,12));\n",
    "plt.title(\"Confustion Matrix for GradientBoostingClassifier\")\n",
    "cmd.plot(ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5085fd67",
   "metadata": {},
   "source": [
    "#### Classification Report for GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c693601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report #Run time -3minutes:47seconds\n",
    "\n",
    "target_names = Install_lbl\n",
    "cr = classification_report(y_test,y_pred,target_names = target_names)\n",
    "print(\"Classification Report for GradientBoostingClassifier\")\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169328cb",
   "metadata": {},
   "source": [
    "### c) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e0a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "\n",
    "lr_c=LogisticRegression(random_state=0)\n",
    "lr_c.fit(X_train,y_train)\n",
    "lr_pred=lr_c.predict(X_test)\n",
    "lr_cm=confusion_matrix(lr_pred,y_test)\n",
    "#cm = confusion_matrix(y_pred,y_test)\n",
    "\n",
    "cmd = ConfusionMatrixDisplay(lr_cm,display_labels =Install_lbl)\n",
    "fig, ax = plt.subplots(figsize=(12,12));\n",
    "plt.title(\"Confustion Matrix for GradientBoostingClassifier\")\n",
    "cmd.plot(ax=ax);\n",
    "lr_ac=accuracy_score(lr_pred, y_test)\n",
    "print('LogisticRegression_accuracy:',lr_ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8e277d",
   "metadata": {},
   "source": [
    "#### Classification Report for LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d14dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report #Run time - 25sec\n",
    "\n",
    "target_names = Install_lbl\n",
    "cr = classification_report(y_test,y_pred,target_names = target_names)\n",
    "print(\"Classification Report for LogisticRegression\")\n",
    "print(cr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
